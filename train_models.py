import pandas as pd
import numpy as np
from pathlib import Path

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.linear_model import SGDClassifier  # âœ… Linear SVM iÃ§in
from sklearn.utils import resample             # âœ… Oversample iÃ§in

# Ä°stersen joblib ile modelleri kaydedebiliriz
try:
    import joblib
    HAS_JOBLIB = True
except ImportError:
    HAS_JOBLIB = False

# ================== AYARLAR ==================
DATA_CSV = Path("combined_with_svm.csv")  # svm_label eklenmiÅŸ dosya
TEST_SIZE_SVM = 0.2
TEST_SIZE_DT = 0.2
RANDOM_STATE = 42

USE_SUBSAMPLE = False      # BÃ¼yÃ¼k veri iÃ§in istersen True yap
SUBSAMPLE_FRAC = 0.2       # frac=0.2 => verinin %20'si ile eÄŸitim (ÅŸu an kullanÄ±lmÄ±yor)
# ============================================

print(f"Veri okunuyor: {DATA_CSV.resolve()}")
df = pd.read_csv(DATA_CSV, header=0, low_memory=False)

# Gereksiz Unnamed kolonlarÄ±nÄ± temizle
df = df.loc[:, ~df.columns.astype(str).str.startswith("Unnamed")]

print("\nBulunan sÃ¼tunlar:")
for c in df.columns:
    print(f"- '{c}'")

# ------------------ OPSÄ°YONEL: SUBSAMPLE ------------------
if USE_SUBSAMPLE:
    df = df.sample(frac=SUBSAMPLE_FRAC, random_state=RANDOM_STATE)
    print(f"\nSubsample uygulandÄ±. Yeni satÄ±r sayÄ±sÄ±: {len(df)}")
# ----------------------------------------------------------


# ---------- Etiket kolonunu akÄ±llÄ± tespit et ----------
def find_label_column(columns) -> str | None:
    """
    SÃ¼tun adlarÄ±nÄ± normalize ederek olasÄ± label/target kolonunu bulmaya Ã§alÄ±ÅŸÄ±r.
    Ã–rn:
      ' Label '           -> 'label'
      'Attack category'   -> 'attackcategory'
    """
    candidates_norm = {
        "label",
        "target",
        "class",
        "attackcategory",
        "attack_cat",
        "attacktype",
    }

    # orijinal -> normalize eÅŸlemesi
    normalized_map = {}
    for col in columns:
        norm = (
            str(col)
            .strip()
            .lower()
            .replace(" ", "")
            .replace("_", "")
        )
        normalized_map[col] = norm

    # Ã–nce birebir Label / Target var mÄ± diye bak
    if "Label" in columns:
        # baÅŸÄ±nda boÅŸluklu hali varsa onu kullan
        return " Label" if " Label" in columns else "Label"
    if "Target" in columns:
        return "Target"

    # Sonra normalize edip adaylarla eÅŸleÅŸtir
    for original, norm in normalized_map.items():
        if norm in candidates_norm:
            print(f"\nOlasÄ± etiket kolonu bulundu: '{original}' (normalize: '{norm}')")
            return original

    # Bulunamazsa None dÃ¶n
    return None


label_col = find_label_column(df.columns)

if label_col is None:
    raise ValueError(
        "\nNe 'Label' ne de 'Target' ne de bilinen isimlerde bir etiket kolonu bulunamadÄ±.\n"
        "YukarÄ±daki sÃ¼tun isimlerine bakÄ±p etiket kolonunun adÄ±nÄ± netleÅŸtirip\n"
        "find_label_column iÃ§indeki candidates_norm set'ine uygun bir anahtar eklemen gerekiyor."
    )

print(f"\nKullanÄ±lacak orijinal etiket kolonu: '{label_col}'")

if "svm_label" not in df.columns:
    raise ValueError("'svm_label' kolonu bulunamadÄ±. Ã–nce svm_label script'ini Ã§alÄ±ÅŸtÄ±rmalÄ±sÄ±n.")

print(f"SVM etiketi kolonu                     : 'svm_label'")


# ================== SINIF GRUPLARI ==================
major_attacks = [
    "DDoS",
    "DoS GoldenEye",
    "DoS Hulk",
    "DoS Slowhttptest",
    "DoS slowloris",
    "FTP-Patator",
    "PortScan",
    "SSH-Patator",
]

rare_attacks = [
    "Bot",
    "Heartbleed",
    "Infiltration",
    "Web Attack â€“ Brute Force",
    "Web Attack - Brute Force",
    "Web Attack â€“ Sql Injection",
    "Web Attack - Sql Injection",
    "Web Attack â€“ XSS",
    "Web Attack - XSS",
]
# ====================================================


# ------------ FEATURE MATRÄ°SÄ°NÄ° HAZIRLA ------------

# Label ve svm_label dÄ±ÅŸÄ±ndaki kolonlar Ã¶zellik adayÄ±
feature_df = df.drop(columns=[label_col, "svm_label"], errors="ignore").copy()

# TÃ¼m kolonlarÄ± numeriÄŸe Ã§evirmeyi dene (non-numeric -> NaN)
for col in feature_df.columns:
    if not np.issubdtype(feature_df[col].dtype, np.number):
        feature_df[col] = pd.to_numeric(feature_df[col], errors="coerce")

# Sonsuz deÄŸerleri (inf, -inf) NaN yap
feature_df.replace([np.inf, -np.inf], np.nan, inplace=True)

# Tamamen NaN olan kolonlarÄ± at
feature_df = feature_df.dropna(axis=1, how="all")

# Kalan NaN'leri 0 ile doldur
feature_df = feature_df.fillna(0.0)

feature_cols = feature_df.columns.tolist()
X_all = feature_df.values

print(f"\nKullanÄ±lan Ã¶zellik sayÄ±sÄ±: {len(feature_cols)}")
print("Ã–rnek feature kolonlarÄ±:", feature_cols[:10])


# ================== OVERSAMPLE FONKSÄ°YONU ==================

def oversample_other_attack(X_train, y_train, random_state=42, factor=20):
    """
    Sadece train set Ã¼zerinde 'other_attack' sÄ±nÄ±fÄ±nÄ± oversample eder.
    factor: other_attack'i yaklaÅŸÄ±k kaÃ§ katÄ±na Ã§Ä±karmak istediÄŸin.
    Ama hedef sayÄ± attack ve benign'den bÃ¼yÃ¼k olmayacak.
    """
    X_df = pd.DataFrame(X_train)
    y_sr = pd.Series(y_train)

    print("\n[Ã–nce] SVM train sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
    print(y_sr.value_counts())

    mask_other = (y_sr == "other_attack")
    mask_attack = (y_sr == "attack")
    mask_benign = (y_sr == "benign")

    n_other = mask_other.sum()
    n_attack = mask_attack.sum()
    n_benign = mask_benign.sum()

    if n_other == 0:
        print("other_attack sÄ±nÄ±fÄ± train set'te yok, oversample yapÄ±lmadÄ±.")
        return X_train, y_train

    # Hedef: other_attack'i factor * n_other seviyesine Ã§Ä±kar,
    # ama yine de attack ve benign'den bÃ¼yÃ¼k olmasÄ±n
    raw_target = n_other * factor
    target_other = min(raw_target, n_attack, n_benign)

    if target_other <= n_other:
        print("other_attack zaten hedef veya Ã¼zerinde, oversample yapÄ±lmadÄ±.")
        return X_train, y_train

    n_new = target_other - n_other
    print(
        f"\nother_attack iÃ§in hedef Ã¶rnek sayÄ±sÄ±: {target_other} "
        f"(ÅŸu an {n_other}), eklenecek yeni Ã¶rnek: {n_new}"
    )

    X_other = X_df[mask_other]
    y_other = y_sr[mask_other]

    X_other_up, y_other_up = resample(
        X_other,
        y_other,
        replace=True,
        n_samples=n_new,
        random_state=random_state
    )

    X_rest = X_df[~mask_other]
    y_rest = y_sr[~mask_other]

    X_bal = pd.concat([X_rest, X_other, X_other_up], ignore_index=True)
    y_bal = pd.concat([y_rest, y_other, y_other_up], ignore_index=True)

    print("\n[Sonra] SVM train sÄ±nÄ±f daÄŸÄ±lÄ±mÄ± (oversample sonrasÄ±):")
    print(y_bal.value_counts())

    return X_bal.values, y_bal.values


# ====================================================
#                   1) SVM EÄÄ°TÄ°MÄ°
# ====================================================

y_svm = df["svm_label"].values

X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(
    X_all,
    y_svm,
    test_size=TEST_SIZE_SVM,
    random_state=RANDOM_STATE,
    stratify=y_svm
)

# ğŸ”¹ Train set Ã¼zerinde other_attack oversample (factor ile ayarlÄ±)
X_train_svm, y_train_svm = oversample_other_attack(
    X_train_svm,
    y_train_svm,
    random_state=RANDOM_STATE,
    factor=20  # gerekirse 10 / 30 vs. deneyebilirsin
)

# âœ… Linear SVM (SGDClassifier ile)
svm_clf = Pipeline([
    ("scaler", StandardScaler()),
    ("svc", SGDClassifier(
        loss="hinge",           # linear SVM
        class_weight="balanced",
        max_iter=1000,
        tol=1e-3,
        random_state=RANDOM_STATE
    ))
])

print("\n=== SVM (linear, 3 sÄ±nÄ±f: benign / attack / other_attack) eÄŸitiliyor ===")
svm_clf.fit(X_train_svm, y_train_svm)

y_pred_svm = svm_clf.predict(X_test_svm)

print("\n--- SVM Classification Report ---")
print(classification_report(y_test_svm, y_pred_svm))

print("--- SVM Confusion Matrix ---")
print(confusion_matrix(y_test_svm, y_pred_svm, labels=["benign", "attack", "other_attack"]))


# ====================================================
#            2) DECISION TREE (ATTACK SUBSET)
# ====================================================

# Sadece major attack sÄ±nÄ±flarÄ±nÄ± iÃ§eren satÄ±rlar
df_dt = df[df[label_col].isin(major_attacks)].copy()

if df_dt.empty:
    raise ValueError("Decision Tree iÃ§in major_attacks sÄ±nÄ±flarÄ±na ait satÄ±r bulunamadÄ±.")

# AynÄ± feature kolonlarÄ±nÄ±, aynÄ± sÄ±rayla kullan
X_dt_all = feature_df.loc[df_dt.index].values
y_dt_all = df_dt[label_col].values

X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(
    X_dt_all,
    y_dt_all,
    test_size=TEST_SIZE_DT,
    random_state=RANDOM_STATE,
    stratify=y_dt_all
)

dt_clf = DecisionTreeClassifier(
    max_depth=None,
    min_samples_leaf=10,
    class_weight="balanced",
    random_state=RANDOM_STATE
)

print("\n=== Decision Tree (major attack tipleri) eÄŸitiliyor ===")
dt_clf.fit(X_train_dt, y_train_dt)

y_pred_dt = dt_clf.predict(X_test_dt)

print("\n--- Decision Tree Classification Report ---")
print(classification_report(y_test_dt, y_pred_dt))

print("--- Decision Tree Confusion Matrix ---")
print(confusion_matrix(y_test_dt, y_pred_dt, labels=major_attacks))


# ====================================================
#         3) ORTAK PREDICTION AKIÅI Ã–RNEK FONKSÄ°YON
# ====================================================

def predict_flow(sample_row: pd.Series):
    """
    Tek bir satÄ±r iÃ§in:
      1) SVM ile benign / attack / other_attack kararÄ±
      2) attack ise Decision Tree ile saldÄ±rÄ± tipini belirler.

    DÃ¶nen:
      - "BENIGN"
      - "OTHER_ATTACK"
      - veya major_attacks listesinden biri
    """
    x = sample_row[feature_cols].values.astype(float).reshape(1, -1)

    svm_pred = svm_clf.predict(x)[0]

    if svm_pred == "benign":
        return "BENIGN"
    elif svm_pred == "other_attack":
        return "OTHER_ATTACK"
    else:
        dt_pred = dt_clf.predict(x)[0]
        return dt_pred


print("\nÃ–rnek ortak prediction (ilk 5 satÄ±r):")
for idx in df.index[:5]:
    row = df.loc[idx]
    final_label = predict_flow(row)
    print(f"Index {idx}: gerÃ§ek={row[label_col]} | svm_label={row['svm_label']} | final={final_label}")


# ====================================================
#                     4) MODELLERÄ° KAYDET
# ====================================================

if HAS_JOBLIB:
    joblib.dump(svm_clf, "svm_model.joblib")
    joblib.dump(dt_clf, "dt_model.joblib")
    joblib.dump(feature_cols, "feature_columns.joblib")
    print("\nModeller ve feature kolon listesi kaydedildi: "
          "svm_model.joblib, dt_model.joblib, feature_columns.joblib")
else:
    print("\njoblib bulunamadÄ±, modeller kaydedilmedi. "
          "Ä°stersen 'pip install joblib' ile kurup tekrar Ã§alÄ±ÅŸtÄ±rabilirsin.")
