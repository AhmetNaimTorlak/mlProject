import pandas as pd
import numpy as np
import joblib
from pathlib import Path
from sklearn.metrics import classification_report, confusion_matrix

# ================== AYARLAR ==================
# EÄŸitimde kullandÄ±ÄŸÄ±n model ve feature dosyalarÄ±
SVM_MODEL_PATH = "svm_model.joblib"
DT_MODEL_PATH = "dt_model.joblib"
FEATURE_COLS_PATH = "feature_columns.joblib"
# ============================================


def normalize_label_str(s):
    """
    Label stringlerini normalize eder:
      - FarklÄ± tire karakterlerini '-' yapar
      - Bozuk 'ï¿½' karakterini '-' ile deÄŸiÅŸtirir
      - BaÅŸtaki/sondaki boÅŸluklarÄ± temizler
    """
    if pd.isna(s):
        return s
    s = str(s)
    # Bozuk karakterleri ve farklÄ± tireleri normalize et
    s = s.replace("ï¿½", "-")
    s = s.replace("â€“", "-")
    s = s.strip()
    return s


# ---- Modelleri ve feature kolonlarÄ±nÄ± yÃ¼kle ----
svm_clf = joblib.load(SVM_MODEL_PATH)
dt_clf = joblib.load(DT_MODEL_PATH)
feature_cols = joblib.load(FEATURE_COLS_PATH)

print("âœ… Modeller ve feature kolonlarÄ± yÃ¼klendi.")
print("Feature sayÄ±sÄ±:", len(feature_cols))

# ---- Test CSV yolunu kullanÄ±cÄ±dan iste ----
test_path_str = input("\nTest iÃ§in kullanacaÄŸÄ±n CSV dosyasÄ±nÄ±n yolunu gir (Ã¶rn: data/benign_only.csv): ").strip()
TEST_CSV = Path(test_path_str)

if not TEST_CSV.exists():
    raise FileNotFoundError(f"Dosya bulunamadÄ±: {TEST_CSV.resolve()}")

print(f"\nðŸ“‚ Test verisi okunuyor: {TEST_CSV.resolve()}")
df_test = pd.read_csv(TEST_CSV, header=0, low_memory=False)
df_test = df_test.loc[:, ~df_test.columns.astype(str).str.startswith("Unnamed")]

print("\nTest dosyasÄ±ndaki sÃ¼tunlar:")
for c in df_test.columns:
    print(f"- '{c}'")

print(f"\nToplam test satÄ±rÄ±: {len(df_test)}")


# ---------- Etiket kolonunu akÄ±llÄ± tespit et ----------
def find_label_column(columns) -> str | None:
    candidates_norm = {
        "label",
        "target",
        "class",
        "attackcategory",
        "attack_cat",
        "attacktype",
    }
    normalized_map = {}
    for col in columns:
        norm = (
            str(col)
            .strip()
            .lower()
            .replace(" ", "")
            .replace("_", "")
        )
        normalized_map[col] = norm

    # Birebir Label / Target var mÄ±?
    if "Label" in columns:
        return " Label" if " Label" in columns else "Label"
    if "Target" in columns:
        return "Target"

    # Normalize edip adaylara bak
    for original, norm in normalized_map.items():
        if norm in candidates_norm:
            return original

    return None


label_col = find_label_column(df_test.columns)
if label_col is not None:
    print(f"\nðŸ”Ž Bulunan etiket kolonu: '{label_col}'")
    # Label stringlerini normalize et
    df_test[label_col] = df_test[label_col].apply(normalize_label_str)
else:
    print("\nâš  Bu test CSV'sinde etiket kolonu bulunamadÄ± (Label/Target yok). "
          "Yine de tahmin yapacaÄŸÄ±z ama metrik hesaplayamayacaÄŸÄ±z.")

# ================== SINIF GRUPLARI ==================
# EÄŸitimde kullandÄ±ÄŸÄ±n gruplarla uyumlu tutuyoruz
major_attacks = [
    "DDoS",
    "DoS GoldenEye",
    "DoS Hulk",
    "DoS Slowhttptest",
    "DoS slowloris",
    "FTP-Patator",
    "PortScan",
    "SSH-Patator",
]

# Web attack'ler ve diÄŸer nadirler (normalize edilmiÅŸ halleri dahil)
rare_attacks = [
    "Bot",
    "Heartbleed",
    "Infiltration",
    # Web Attack'ler - normalize edilmiÅŸ tire ile
    "Web Attack - Brute Force",
    "Web Attack - Sql Injection",
    "Web Attack - XSS",
    # OlasÄ± eski varyantlar (gÃ¼venlik iÃ§in ekliyorum)
    "Web Attack â€“ Brute Force",
    "Web Attack â€“ Sql Injection",
    "Web Attack â€“ XSS",
]
# ====================================================


def make_svm_label_from_original(lbl) -> str:
    """Test setindeki orijinal label'dan benign/attack/other_attack Ã¼retir."""
    if pd.isna(lbl):
        return "other_attack"
    s = normalize_label_str(lbl)
    if s == "BENIGN":
        return "benign"
    elif s in rare_attacks:
        return "other_attack"
    else:
        return "attack"


# ------------ FEATURE MATRÄ°SÄ°NÄ° HAZIRLA ------------

# YalnÄ±zca eÄŸitimde kullandÄ±ÄŸÄ±mÄ±z kolonlarÄ± al
missing_cols = [c for c in feature_cols if c not in df_test.columns]
if missing_cols:
    print("\nâš  UyarÄ±: Test CSV iÃ§inde aÅŸaÄŸÄ±daki feature kolonlarÄ± yok:")
    for c in missing_cols:
        print("  -", c)
    print("Bu kolonlar 0 ile doldurulacak (eÄŸer Ã§oksa schema farkÄ± var demektir).")

# Eksik feature kolonlarÄ±nÄ± oluÅŸturup 0 ile doldur
for c in missing_cols:
    df_test[c] = 0.0

# Sadece feature_cols sÄ±rasÄ±yla alÄ±nÄ±r
feature_df_test = df_test[feature_cols].copy()

# Numerik dÃ¶nÃ¼ÅŸÃ¼m, inf temizliÄŸi, NaN doldurma
for col in feature_df_test.columns:
    if not np.issubdtype(feature_df_test[col].dtype, np.number):
        feature_df_test[col] = pd.to_numeric(feature_df_test[col], errors="coerce")

feature_df_test.replace([np.inf, -np.inf], np.nan, inplace=True)
feature_df_test = feature_df_test.fillna(0.0)

X_test = feature_df_test.values

print(f"\nTest iÃ§in kullanÄ±lan feature sayÄ±sÄ±: {len(feature_cols)}")
print("Ã–rnek feature kolonlarÄ±:", feature_cols[:10])

# ====================================================
#           1) SVM TAHMÄ°NÄ° (benign/attack/other_attack)
# ====================================================

svm_pred = svm_clf.predict(X_test)

print("\nðŸ”¹ SVM tahmin daÄŸÄ±lÄ±mÄ±:")
unique, counts = np.unique(svm_pred, return_counts=True)
for u, c in zip(unique, counts):
    print(f"  {u}: {c}")

# ====================================================
#      2) SVM+DT PIPELINE (final prediction) TAHMÄ°NÄ°
# ====================================================

final_pred = []

# DT'yi toplu Ã§aÄŸÄ±rmak iÃ§in Ã¶nce attack index'lerini bulalÄ±m
attack_indices = np.where(svm_pred == "attack")[0]
if len(attack_indices) > 0:
    X_attack = X_test[attack_indices]
    dt_pred_attack = dt_clf.predict(X_attack)
else:
    dt_pred_attack = np.array([])

attack_idx_to_dt = {idx: dt_pred_attack[i] for i, idx in enumerate(attack_indices)}

for i in range(len(df_test)):
    sp = svm_pred[i]
    if sp == "benign":
        final_pred.append("BENIGN")
    elif sp == "other_attack":
        final_pred.append("OTHER_ATTACK")
    else:  # "attack"
        final_pred.append(attack_idx_to_dt[i])

final_pred = np.array(final_pred)

print("\nðŸ”¹ Final prediction (SVM+DT) daÄŸÄ±lÄ±mÄ±:")
unique_f, counts_f = np.unique(final_pred, return_counts=True)
for u, c in zip(unique_f, counts_f):
    print(f"  {u}: {c}")

# ====================================================
#          3) ETÄ°KET VARSA METRÄ°KLERÄ° HESAPLA
# ====================================================

if label_col is not None:
    y_true_orig = df_test[label_col].values

    # SVM iÃ§in: orijinal label'dan benign/attack/other_attack map et
    y_true_svm = np.array([make_svm_label_from_original(v) for v in y_true_orig])

    print("\n=== SVM (3 sÄ±nÄ±f) - Test CSV Ã¼zerinde performans ===")
    print(classification_report(y_true_svm, svm_pred, zero_division=0))
    print("Confusion Matrix (rows=true, cols=pred):")
    print(confusion_matrix(y_true_svm, svm_pred, labels=["benign", "attack", "other_attack"]))

    print("\n=== SVM+DT Final Prediction - Test CSV Ã¼zerinde ===")
    print("Not: Burada orijinal label ile final_prediction karÅŸÄ±laÅŸtÄ±rÄ±lÄ±yor.")
    print(classification_report(y_true_orig, final_pred, zero_division=0))
    print("Confusion Matrix (rows=true, cols=pred):")
    labels_final = sorted(list(set(y_true_orig) | set(final_pred)), key=lambda x: str(x))
    print("KullanÄ±lan label sÄ±rasÄ±:", labels_final)
    print(confusion_matrix(y_true_orig, final_pred, labels=labels_final))
else:
    print("\nâš  Etiket kolonu bulunamadÄ±ÄŸÄ± iÃ§in metrik hesaplanmadÄ±. "
          "YukarÄ±daki daÄŸÄ±lÄ±mlarÄ± (SVM ve final prediction) inceleyebilirsin.")
